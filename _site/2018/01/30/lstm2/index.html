<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
    
  <!-- Enable responsiveness on mobile devices-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">-->
 

  <title>
    
      Sequence classification with LSTM &middot; 
      pyVision
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/pyVision/public/css/poole.css">
  <link rel="stylesheet" href="/pyVision/public/css/syntax.css">
  <link rel="stylesheet" href="/pyVision/public/css/lanyon.css">
  <!--<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">-->
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/pyVisionpublic/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/pyVisionpublic/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js"></script>
<script type="text/x-mathjax-config">
   MathJax.Hub.Config({ 
                config: ["MMLorHTML.js"], 
                extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"], 
                jax: ["input/TeX"], 
                tex2jax: { 
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ], 
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ], 
                    processEscapes: false 
                }, 
                TeX: { 
                    TagSide: "right", 
                    TagIndent: ".8em", 
                    MultLineWidth: "85%", 
                    equationNumbers: { 
                       autoNumber: "AMS", 
                    }, 
                    unicode: { 
                       fonts: "STIXGeneral,'Arial Unicode MS'" 
                    } 
                }, 
                showProcessingMessages: false 
            }); 
</script>
<!--<script src="/pyVision/javascripts/gitdata.js"></script>-->
	<script type="text/javascript">
    	$(function() {
        $("#display-projects").getRepos("pi19404"); //Add your github username.
    	});
	</script>
<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link href='http://alexgorbatchev.com/pub/sh/2.1.364/styles/shCore.css' rel='stylesheet' type='text/css'/> 
<link href='http://alexgorbatchev.com/pub/sh/2.1.364/styles/shThemeDefault.css' rel='stylesheet' type='text/css'/> 
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shCore.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushCpp.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushCSharp.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushCss.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushJava.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushJScript.js' type='text/javascript' /> </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushPhp.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushPython.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushRuby.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushSql.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushVb.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushXml.js' type='text/javascript' > </script>
<script src='http://alexgorbatchev.com/pub/sh/2.1.364/scripts/shBrushPerl.js' type='text/javascript' > </script>
<script language='javascript'> 
SyntaxHighlighter.config.bloggerMode = false;
SyntaxHighlighter.all();
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-38535188-2', 'auto');
  ga('send', 'pageview');

</script>
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">





  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/pyVision/">Home </a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/pyVision//about/">About</a>
        
      
    
      
    
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
      
    

    <!-- <a class="sidebar-nav-item" href="http://www.github.com/pi19404/pyVision/zipball/master">Download</a>
    <a class="sidebar-nav-item" href="http://www.github.com/pi19404/pyVision">GitHub project</a> -->
    <!-- <a class="sidebar-nav-item" ><g:plusone size="medium">Categories</g:plusone> </a> -->

    <div >
      <nav class="sidebar-nav-item">
        <g:plusone size="medium">Categories</g:plusone>
        
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/ai">
            AI
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/embedded-firmware">
            Embedded Firmware
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/linux">
            Linux
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/raspberry-pi">
            Raspberry PI
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/signal-processing">
            Signal Processing
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/software">
            Software
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/software-installation">
            Software Installation
         </a>
        
         
         <a class="sidebar-nav-item" href="/pyVision/category1/software-installation">
            Software installation
         </a>
        
      </nav>
    
    </div>
    <!-- <div>
      <ul>
        
        
        <li><a href="/pyVision//category/AI/index.html">AI</a></li>
        
        
        <li><a href="/pyVision//category/Signal+Processing/index.html">Signal Processing</a></li>
        
        
        <li><a href="/pyVision//category/Raspberry+PI/index.html">Raspberry PI</a></li>
        
        
        <li><a href="/pyVision//category/Linux/index.html">Linux</a></li>
        
        
        <li><a href="/pyVision//category/Software/index.html">Software</a></li>
        
        
        <li><a href="/pyVision//category/Embedded+Firmware/index.html">Embedded Firmware</a></li>
        
        
        <li><a href="/pyVision//category/Software+Installation/index.html">Software Installation</a></li>
        
        
        <li><a href="/pyVision//category/Software+installation/index.html">Software installation</a></li>
        
        </ul>
    
    </div> -->
<a class="sidebar-nav-item" >
<div class='g-person' data-href='https://plus.google.com/115840780257908006648' data-layout='landscape' data-rel='author' data-showcoverphoto='false' data-showtagline='false' data-theme='dark' data-width='100'></a>
</div>

<div class='widget-content'>
<script type="text/javascript" src="http://jj.revolvermaps.com/2/1.js?i=9bj6dpaloim&amp;s=220&amp;m=7&amp;v=true&amp;r=true&amp;b=ffffff&amp;n=false&amp;c=ff0000" async="async"></script>
</div>

<script type="text/javascript">
function cantload() {
img = document.getElementById("clustrMapsImg");
img.onerror = null;
img.src = "http://www2.clustrmaps.com/images/clustrmaps-back-soon.jpg";
document.getElementById("clustrMapsLink").href = "http://www2.clustrmaps.com";
}
img = document.getElementById("clustrMapsImg");
img.onerror = cantload;
</script>
<div class='widget-content'>
<div id="clustrmaps-widget"></div><script type="text/javascript">var _clustrmaps = {'url' : 'http://pi-virtualworld.blogspot.com', 'user' : 1165875, 'server' : '3', 'id' : 'clustrmaps-widget', 'version' : 1, 'date' : '2015-04-05', 'lang' : 'en', 'corners' : 'square' };(function (){ var s = document.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'http://www3.clustrmaps.com/counter/map.js'; var x = document.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x);})();</script><noscript><a href="http://www3.clustrmaps.com/user/ace11ca33"><img src="http://www3.clustrmaps.com/stats/maps-no_clusters/pi-virtualworld.blogspot.com-thumb.jpg" alt="Locations of visitors to this page" /></a></noscript>
</a>

<!-- Copyright (c)2009 Site Meter -->


</div>

<div class='widget-content'>
<script type="text/javascript" src="http://feedjit.com/serve/?vv=1022&amp;tft=3&amp;dd=0&amp;wid=f31e21a2d981f025&amp;pid=0&amp;proid=0&amp;bc=000000&amp;tc=F5F5F5&amp;brd1=454545&amp;lnk=C95050&amp;hc=FFFFFF&amp;hfc=5C5A5A&amp;btn=8A0214&amp;ww=200&amp;went=10"></script><noscript><a href="http://feedjit.com/">Feedjit Live Blog Stats</a></noscript>
</div>
 
<!-- Site Meter -->
<script type="text/javascript" src="http://s30.sitemeter.com/js/counter.js?site=s30pi19404">
</script>
<noscript>
<a href="http://s30.sitemeter.com/stats.asp?site=s30pi19404" target="_top">
<img src="http://s30.sitemeter.com/meter.asp?site=s30pi19404" alt="Site Meter" border="0"/></a>
</noscript>   
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2022. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      
        <div class="container">
          <h1 class="header">
            <a href="/" title="Home">pyVision</a></br>
            <small>A Machine Learning and Signal Processing toolbox</small>
          </h1>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/pi19404/pyVision/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/pi19404/pyVision/tarball/master" id="download-tar-gz" class="button"><span>Download.tar.gz</span></a>
          <a href="https://github.com/pi19404/pyVision" id="view-on-github" class="button"><span>View on GitHub</span></a>
		
	   <hr>
          </section>
    
	</br>	</br>
      <div class="content">
        <article class="post">
  <h1 class="post-title">Sequence classification with LSTM</h1>
  <span class="post-date">30 Jan 2018</span>
  <p>In this article, we will look at how to use LSTM recurrent neural network models for sequence classification problems using the Keras deep learning library</p>

<p>A standard dataset used to demonstrate sequence classification is sentiment classficiation on IMDB movie review dataset.</p>

<p>Each movie review is a sentense and sentiment associated with each movie review must be determined.The training dataset consists of movie review and associated sentiment.A sentense is modelled as a sequence of words and hence we look sequence classification problem.</p>

<p>Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer “3” encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: “only consider the top 10,000 most common words, but eliminate the top 20 most common words”.</p>

<p>A representation of review of imdb database is as follows</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
</code></pre></div></div>

<p>For this example we will only take first 50 words of the review . we will pad dataset to a maximum review length in words.</p>

<p>The same review is represented as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[    1    14    22    16    43   530   973  1622  1385    65   458  4468
    66  3941     4   173    36   256     5    25   100    43   838   112
    50   670 22665     9    35   480   284     5   150     4   172   112
   167 21631   336   385    39     4   172  4536  1111    17   546    38
    13   447]
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import numpy as np

from keras.datasets import imdb
from keras.preprocessing import sequence

import numpy as np
import keras
from keras.datasets import reuters
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.preprocessing.text import Tokenizer

#from matplotlib import pyplot
# load the dataset
(X_train, y_train), (X_test, y_test) = imdb.load_data()
print("Training data: ")
print(X_train.shape)
print("Testing data: ")
print(X_test.shape)

num_classes = np.max(y_train) + 1
print(num_classes, 'classes')

max_words = 50
X_train = sequence.pad_sequences(X_train, maxlen=max_words,padding="post",truncating="post")
X_test = sequence.pad_sequences(X_test, maxlen=max_words,padding="post",truncating="post")

</code></pre></div></div>

<p>A sentense can be modelled as sequence of words indexes,however there is no contextual relation between index 1 and index 2 .</p>

<p>We will use LSTM to model sequences,where input to LSTM is sequence of indexs representing words and output is sentiment associated with the sentense</p>

<p>Input to LSTM is a 3D tensor with shape (batch_size, timesteps, input_dim). In out present case the batch_size will be the size of training data.Timesteps will be sequence length 50 and input dimensions will be 1 since the sequences as integer indexes</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

def save_model(model, filename):
    logging.info("saving  the model %s" % (filename))
    model_json = model.to_json()
    with open(filename + '.model', "w") as json_file:
        json_file.write(model_json)
        json_file.close();
    model.save_weights(filename + ".weights")

def load_model(filename):
    logging.info("loading the model %s" % (filename))
    json_file = open(filename + '.model', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights(filename + ".weights")

    return loaded_model;
		
model=Sequential()

model.add(LSTM(50,return_sequences=False,input_shape=(X_train.shape[1],X_train.shape[2])))
model.add(Dense(num_classes, activation='softmax'))
print(model.summary())
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train,y_train,epochs=1000, batch_size=100, verbose=1)

save_model(model,"/tmp/model1")

model.evaluate(X_test,y_test)

</code></pre></div></div>

<p>We obtain a training accuracy of 58% on the training data after 75 iterations</p>

<p>In this approach words are simply represented as word indexes and sequence of words are used to train LSTM . The word indexes are themselves do not represent any information are in general orthogonal . Word indexes may be represented as one hot vector encoding,but for large dictionary sizes such a representation will be too large and occury lot of memory and computational resources.</p>

<p><strong>Word Embeddings</strong></p>

<p>A word embedding is a class of approaches for representing words and documents using a dense vector representation. The position of word in N dimensional space is 
referred to as its embedding. The word embeddings are learned from text and is based on the words that surround the word when it is used ie context in which words are used.</p>

<p>If we represent words as index of vocubulary we end up with large dimensional sparse vector using techniques like one hot encoding.The idea of word vectors can also be viewed
as method to cast a high dimensional sparse representation to a low dimensional dense representation.</p>

<p>Keras offers an Embedding layer that can be used for neural networks on text data.</p>

<p>The output of the Embedding layer is a 2D vector with one embedding for each word in the input sequence of words (input document).</p>

<p>The parameters of Keras Embedding Layer is</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)
</code></pre></div></div>

<p>where</p>

<ul>
  <li>input_dim is the vocabulary size</li>
  <li>output_dim is the dimension of the output embedding</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

def save_model(model, filename):
    logging.info("saving  the model %s" % (filename))
    model_json = model.to_json()
    with open(filename + '.model', "w") as json_file:
        json_file.write(model_json)
        json_file.close();
    model.save_weights(filename + ".weights")

def load_model(filename):
    logging.info("loading the model %s" % (filename))
    json_file = open(filename + '.model', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights(filename + ".weights")

    return loaded_model;
		
X_train=np.reshape(X_train,(X_train.shape[0],max_words));
X_test=np.reshape(X_test,(X_test.shape[0],max_words));


print("input tensor")
print(X_train.shape),y_train.shape

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dense, Embedding

model=Sequential()

model.add(Embedding(vocab_size,300,input_length=max_words))
model.add(LSTM(128,return_sequences=False,input_shape=(300,max_words)))
model.add(Dense(num_classes, activation='softmax'))
print(model.summary())
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train,y_train,epochs=1000, batch_size=100, verbose=1)

save_model(model,"/tmp/model1")

model.evaluate(X_test,y_test)

</code></pre></div></div>

<p>We can see that by adding embedding layer at 1 iterations we obtained an accuracy of  73% . Thus by simply adding a embedding layer that encapsulates context of words to arrive at word vector embedding provides a significantly higher accuracy.</p>

<p><strong>References</strong></p>

<ul>
  <li>https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/</li>
  <li>http://pi19404.github.io/pyVision/2017/05/13/spacy1/</li>
  <li>https://keras.io/preprocessing/sequence/</li>
  <li>https://sandipanweb.wordpress.com/2017/03/30/sentiment-analysis-using-linear-model-classifier-with-hinge-loss-and-l1-penalty-with-language-model-features-and-stochastic-gradient-descent-in-python/</li>
</ul>

</article>
<div id="page-navigation"> 
        <div class="clear">&nbsp;</div> 
        <div class="left"> 
         
                <a href="/pyVision//2017/05/24/javaaes/" title="Previous Post: 
Java AES encryption and decryption">&laquo; Java AES encryption and decryption</a> 
         
        </div> 

        <div class="right"> 
         
                <a href="/pyVision//2018/01/30/lstm3/" title="next Post: 
Using Pre Trained Word Vector Embeddings for Sequence Classification using LSTM">Using Pre Trained Word Vector Embeddings for Sequence Classification using LSTM &raquo; </a> 
         
        </div> 
        <div class="clear">&nbsp;</div> 
</div> 
<div id="disqus_thread"></div>
		<script type="text/javascript">
			/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
			var disqus_shortname = 'pi19404'; // required: replace example with your forum shortname
    			var disqus_identifier = '/2018/01/30/lstm2/';
    			var disqus_url = 'http://pyvision.github.com/2018/01/30/lstm2/';       
 
			/* * * DON'T EDIT BELOW THIS LINE * * */
			(function() {
				var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
				dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
				(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
			})();
		</script>
		<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>





      </div>
    </div>

      
       <footer>
          pyVision is maintained by <a href="https://github.com/pi19404">pi19404</a><br>
        </footer>
    
    </div>
 <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = true;
        }, false);
      })(document);
    </script>
<script type="text/javascript">
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'pyvision'; // required: replace example with your forum shortname
    var disqus_identifier = '/2018/01/30/lstm2/';
    var disqus_url = 'http://pyvision.github.com/2018/01/30/lstm2/';
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
    </script>

  </body>
</html>
